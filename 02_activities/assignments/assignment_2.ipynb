{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assigment, we will work with the *Adult* data set. Please download the data from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/2/adult). Extract the data files into the subdirectory: `../05_src/data/adult/` (relative to `./05_src/`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "\n",
    "Assuming that the files `adult.data` and `adult.test` are in `../05_src/data/adult/`, then you can use the code below to load them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "columns = [\n",
    "    'age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n",
    "    'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week',\n",
    "    'native-country', 'income'\n",
    "    ]\n",
    "adult_dt = (pd.read_csv('../../05_src/data/adult/adult.data', header = None, names = columns)\n",
    "            .assign(income = lambda x: (x.income.str.strip() == '>50K')*1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get X and Y\n",
    "\n",
    "Create the features data frame and target data:\n",
    "\n",
    "+ Create a dataframe `X` that holds the features (all columns that are not `income`).\n",
    "+ Create a dataframe `Y` that holds the target data (`income`).\n",
    "+ From `X` and `Y`, obtain the training and testing data sets:\n",
    "\n",
    "    - Use a train-test split of 70-30%. \n",
    "    - Set the random state of the splitting function to 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (22792, 14)\n",
      "X_test shape: (9769, 14)\n",
      "Y_train shape: (22792, 1)\n",
      "Y_test shape: (9769, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# reate a dataframe `X` that holds the features\n",
    "X = adult_dt.drop(columns=['income'])\n",
    "\n",
    "# Create a dataframe `Y` that holds the target data\n",
    "Y = adult_dt[['income']]\n",
    "\n",
    "# Obtain the training and testing data sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting data sets to confirm\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"Y_train shape: {Y_train.shape}\")\n",
    "print(f\"Y_test shape: {Y_test.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random States\n",
    "\n",
    "Please comment: \n",
    "\n",
    "+ What is the [random state](https://scikit-learn.org/stable/glossary.html#term-random_state) of the [splitting function](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)? \n",
    "+ Why is it [useful](https://en.wikipedia.org/wiki/Reproducibility)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ The random state of the splitting function is a way to control the randomness of the data splitting process. It allows to specify a seed or initial state for the random number generator used to shuffle and split the data.\n",
    "+ It's useful for:\n",
    "    * Consistency of results, as the use of a fixed random state ensures that experiments can be repeated by others or by you later under the same conditions. This is crucial to verify the robustness of the model and results.\n",
    "    * Model comparisons, because when testing multiple models or algorithms, having a fixed random state ensures that each model is trained and tested on the same data splits, making performance comparisons fair and unbiased.\n",
    "    * Bug tracking, because if a problem occurs in the model, being able to reproduce the exact conditions under which the problem occurred makes debugging easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Create a [Column Transformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) that treats the features as follows:\n",
    "\n",
    "- Numerical variables\n",
    "\n",
    "    * Apply [KNN-based imputation for completing missing values](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html):\n",
    "        \n",
    "        + Consider the 7 nearest neighbours.\n",
    "        + Weight each neighbour by the inverse of its distance, causing closer neigbours to have more influence than more distant ones.\n",
    "    * [Scale features using statistics that are robust to outliers](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler).\n",
    "\n",
    "- Categorical variables: \n",
    "    \n",
    "    * Apply a [simple imputation strategy](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer):\n",
    "\n",
    "        + Use the most frequent value to complete missing values, also called the *mode*.\n",
    "\n",
    "    * Apply [one-hot encoding](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html):\n",
    "        \n",
    "        + Handle unknown labels if they exist.\n",
    "        + Drop one column for binary variables.\n",
    "    \n",
    "    \n",
    "The column transformer should look like this:\n",
    "\n",
    "![](./images/assignment_2__column_transformer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define the feature columns\n",
    "numerical_features = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "categorical_features = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
    "\n",
    "# Create a Column Transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num_transforms', \n",
    "         Pipeline([\n",
    "             ('imputer', KNNImputer(n_neighbors=7, weights='distance')),\n",
    "             ('scaler', RobustScaler())\n",
    "         ]), \n",
    "         numerical_features),\n",
    "        ('cat_transforms', \n",
    "         Pipeline([\n",
    "             ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "             ('encoder', OneHotEncoder(handle_unknown='ignore', drop='if_binary'))\n",
    "         ]), \n",
    "         categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/assignment_2__column_transformer_mine.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Pipeline\n",
    "\n",
    "Create a [model pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html): \n",
    "\n",
    "+ Add a step labelled `preprocessing` and assign the Column Transformer from the previous section.\n",
    "+ Add a step labelled `classifier` and assign a [`RandomForestClassifier()`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) to it.\n",
    "\n",
    "The pipeline looks like this:\n",
    "\n",
    "![](./images/assignment_2__pipeline.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the model pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/assignment_2__pipeline_mine.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation\n",
    "\n",
    "Evaluate the model pipeline using [`cross_validate()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html):\n",
    "\n",
    "+ Measure the following [preformance metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values): negative log loss, ROC AUC, accuracy, and balanced accuracy.\n",
    "+ Report the training and validation results. \n",
    "+ Use five folds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_neg_log_loss</th>\n",
       "      <th>train_neg_log_loss</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>train_balanced_accuracy</th>\n",
       "      <th>experiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.129849</td>\n",
       "      <td>0.183836</td>\n",
       "      <td>-0.357675</td>\n",
       "      <td>-0.081189</td>\n",
       "      <td>0.904384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.850625</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.774484</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.631899</td>\n",
       "      <td>0.179607</td>\n",
       "      <td>-0.369239</td>\n",
       "      <td>-0.081516</td>\n",
       "      <td>0.901079</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.850406</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.771881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.590545</td>\n",
       "      <td>0.177043</td>\n",
       "      <td>-0.375988</td>\n",
       "      <td>-0.081469</td>\n",
       "      <td>0.901378</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.854103</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.776017</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.869196</td>\n",
       "      <td>0.189193</td>\n",
       "      <td>-0.356791</td>\n",
       "      <td>-0.082511</td>\n",
       "      <td>0.907250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.859807</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.782859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.906405</td>\n",
       "      <td>0.182270</td>\n",
       "      <td>-0.380379</td>\n",
       "      <td>-0.081368</td>\n",
       "      <td>0.902299</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.856077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.776089</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_neg_log_loss  train_neg_log_loss  test_roc_auc  \\\n",
       "0  8.129849    0.183836          -0.357675           -0.081189      0.904384   \n",
       "1  8.631899    0.179607          -0.369239           -0.081516      0.901079   \n",
       "2  8.590545    0.177043          -0.375988           -0.081469      0.901378   \n",
       "3  8.869196    0.189193          -0.356791           -0.082511      0.907250   \n",
       "4  8.906405    0.182270          -0.380379           -0.081368      0.902299   \n",
       "\n",
       "   train_roc_auc  test_accuracy  train_accuracy  test_balanced_accuracy  \\\n",
       "0            1.0       0.850625        0.999945                0.774484   \n",
       "1            1.0       0.850406        1.000000                0.771881   \n",
       "2            1.0       0.854103        0.999945                0.776017   \n",
       "3            1.0       0.859807        1.000000                0.782859   \n",
       "4            1.0       0.856077        1.000000                0.776089   \n",
       "\n",
       "   train_balanced_accuracy  experiment  \n",
       "0                 0.999887           1  \n",
       "1                 1.000000           1  \n",
       "2                 0.999887           1  \n",
       "3                 1.000000           1  \n",
       "4                 1.000000           1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, log_loss, roc_auc_score, accuracy_score, balanced_accuracy_score\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "scoring = [\n",
    "    'neg_log_loss',\n",
    "    'roc_auc',\n",
    "    'accuracy',\n",
    "    'balanced_accuracy'\n",
    "]\n",
    "\n",
    "res_simple_dict = cross_validate(pipeline, X_train, Y_train, cv = 5, scoring = scoring, return_train_score=True)\n",
    "res_simple = pd.DataFrame(res_simple_dict).assign(experiment = 1)\n",
    "res_simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the fold-level results as a pandas data frame and sorted by negative log loss of the test (validation) set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_neg_log_loss</th>\n",
       "      <th>train_neg_log_loss</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>train_balanced_accuracy</th>\n",
       "      <th>experiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.906405</td>\n",
       "      <td>0.182270</td>\n",
       "      <td>-0.380379</td>\n",
       "      <td>-0.081368</td>\n",
       "      <td>0.902299</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.856077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.776089</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.590545</td>\n",
       "      <td>0.177043</td>\n",
       "      <td>-0.375988</td>\n",
       "      <td>-0.081469</td>\n",
       "      <td>0.901378</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.854103</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.776017</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.631899</td>\n",
       "      <td>0.179607</td>\n",
       "      <td>-0.369239</td>\n",
       "      <td>-0.081516</td>\n",
       "      <td>0.901079</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.850406</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.771881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.129849</td>\n",
       "      <td>0.183836</td>\n",
       "      <td>-0.357675</td>\n",
       "      <td>-0.081189</td>\n",
       "      <td>0.904384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.850625</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.774484</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.869196</td>\n",
       "      <td>0.189193</td>\n",
       "      <td>-0.356791</td>\n",
       "      <td>-0.082511</td>\n",
       "      <td>0.907250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.859807</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.782859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_neg_log_loss  train_neg_log_loss  test_roc_auc  \\\n",
       "4  8.906405    0.182270          -0.380379           -0.081368      0.902299   \n",
       "2  8.590545    0.177043          -0.375988           -0.081469      0.901378   \n",
       "1  8.631899    0.179607          -0.369239           -0.081516      0.901079   \n",
       "0  8.129849    0.183836          -0.357675           -0.081189      0.904384   \n",
       "3  8.869196    0.189193          -0.356791           -0.082511      0.907250   \n",
       "\n",
       "   train_roc_auc  test_accuracy  train_accuracy  test_balanced_accuracy  \\\n",
       "4            1.0       0.856077        1.000000                0.776089   \n",
       "2            1.0       0.854103        0.999945                0.776017   \n",
       "1            1.0       0.850406        1.000000                0.771881   \n",
       "0            1.0       0.850625        0.999945                0.774484   \n",
       "3            1.0       0.859807        1.000000                0.782859   \n",
       "\n",
       "   train_balanced_accuracy  experiment  \n",
       "4                 1.000000           1  \n",
       "2                 0.999887           1  \n",
       "1                 1.000000           1  \n",
       "0                 0.999887           1  \n",
       "3                 1.000000           1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted = res_simple.sort_values(by='test_neg_log_loss', ascending=True)\n",
    "df_sorted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the mean of each metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time                   8.625579\n",
       "score_time                 0.182390\n",
       "test_neg_log_loss         -0.368014\n",
       "train_neg_log_loss        -0.081610\n",
       "test_roc_auc               0.903278\n",
       "train_roc_auc              1.000000\n",
       "test_accuracy              0.854204\n",
       "train_accuracy             0.999978\n",
       "test_balanced_accuracy     0.776266\n",
       "train_balanced_accuracy    0.999955\n",
       "experiment                 1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_simple.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the same performance metrics (negative log loss, ROC AUC, accuracy, and balanced accuracy) using the testing data `X_test` and `Y_test`. Display results as a dictionary.\n",
    "\n",
    "*Tip*: both, `roc_auc()` and `neg_log_loss()` will require prediction scores from `pipe.predict_proba()`. However, for `roc_auc()` you should only pass the last column `Y_pred_proba[:, 1]`. Use `Y_pred_proba` with `neg_log_loss()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg_log_loss': 0.39726506589398913,\n",
       " 'roc_auc': 0.8999828704291436,\n",
       " 'accuracy': 0.8551540587572934,\n",
       " 'balanced_accuracy': 0.7751631656838177}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the pipeline with training data\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions\n",
    "Y_pred_proba = pipeline.predict_proba(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "neg_log_loss = log_loss(Y_test, Y_pred_proba)\n",
    "roc_auc = roc_auc_score(Y_test, Y_pred_proba[:, 1])\n",
    "accuracy = accuracy_score(Y_test, pipeline.predict(X_test))\n",
    "balanced_accuracy = balanced_accuracy_score(Y_test, pipeline.predict(X_test))\n",
    "\n",
    "# Display results as a dictionary\n",
    "results_dict = {\n",
    "    'neg_log_loss': neg_log_loss,\n",
    "    'roc_auc': roc_auc,\n",
    "    'accuracy': accuracy,\n",
    "    'balanced_accuracy': balanced_accuracy\n",
    "}\n",
    "\n",
    "results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Recoding\n",
    "\n",
    "In the first code chunk of this document, we loaded the data and immediately recoded the target variable `income`. Why is this [convenient](https://scikit-learn.org/stable/modules/model_evaluation.html#binary-case)?\n",
    "\n",
    "The specific line was:\n",
    "\n",
    "```\n",
    "adult_dt = (pd.read_csv('../05_src/data/adult/adult.data', header = None, names = columns)\n",
    "              .assign(income = lambda x: (x.income.str.strip() == '>50K')*1))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recording the target variable immediately after data is loaded is convenient because it combines data transformation with loading, simplifies processing and analysis, avoids redundancy, ensures consistency, and improves code readability and maintainability. This approach is a good practice in data preprocessing workflows, ensuring efficiency and clarity in data-driven projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criteria\n",
    "\n",
    "|Criteria|Complete|Incomplete|\n",
    "|---------------------|----|----|\n",
    "|Evaluation of model pipeline |Model pipeline was evaluated correctly.|Model pipeline was not evaluated correctly.|\n",
    "|Explanation of answer|Answer was concise and explained the learner's reasoning in depth.|Answer was not concise and did not explained the learner's reasoning in depth.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Information\n",
    "\n",
    "ðŸš¨ **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** ðŸš¨ for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "### Submission Parameters:\n",
    "* Submission Due Date: `HH:MM AM/PM - DD/MM/YYYY`\n",
    "* The branch name for your repo should be: `assignment-2`\n",
    "* What to submit for this assignment:\n",
    "    * This Jupyter Notebook (assignment_2.ipynb) should be populated and should be the only change in your pull request.\n",
    "* What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/production/pull/<pr_id>`\n",
    "    * Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "Checklist:\n",
    "- [ ] Created a branch with the correct naming convention.\n",
    "- [ ] Ensured that the repository is public.\n",
    "- [ ] Reviewed the PR description guidelines and adhered to them.\n",
    "- [ ] Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack at `#cohort-3-help`. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "Becker,Barry and Kohavi,Ronny. (1996). Adult. UCI Machine Learning Repository. https://doi.org/10.24432/C5XW20."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
